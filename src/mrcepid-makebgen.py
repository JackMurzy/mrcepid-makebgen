#!/usr/bin/env python
# mrcepid-collapsevariants 0.0.1
# Generated by dx-app-wizard.
#
# Author: Eugene Gardner (eugene.gardner at mrc.epid.cam.ac.uk)
#
# DNAnexus Python Bindings (dxpy) documentation:
#   http://autodoc.dnanexus.com/bindings/python/current/

import dxpy
import subprocess
import os
import gzip
import csv
import math
from concurrent import futures
from concurrent.futures import ThreadPoolExecutor

# This is to generate a global CHROMOSOMES variable for parallelisation
CHROMOSOMES = list(range(1,23)) # Is 0 based on the right coordinate...? (So does 1..22)
CHROMOSOMES.extend(['X'])
CHROMOSOMES = list(map(str, CHROMOSOMES))


# This function runs a command on an instance, either with or without calling the docker instance we downloaded
# By default, commands are not run via Docker, but can be changed by setting is_docker = True
def run_cmd(cmd: str, is_docker: bool = False) -> None:

    if is_docker:
        # -v here mounts a local directory on an instance (in this case the home dir) to a directory internal to the
        # Docker instance named /test/. This allows us to run commands on files stored on the AWS instance within Docker
        cmd = "docker run " \
              "-v /home/dnanexus:/test " \
              "egardner413/mrcepid-filtering " + cmd

    # Standard python calling external commands protocol
    print(cmd)
    proc = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    stdout, stderr = proc.communicate()

    # If the command doesn't work, print the error stream and close the AWS instance out with 'dxpy.AppError'
    if proc.returncode != 0:
        print("The following cmd failed:")
        print(cmd)
        print("STDERROR follows\n")
        print(stderr.decode('utf-8'))
        print(stdout.decode('utf-8'))
        raise dxpy.AppError("Failed to run properly...")


def purge_file(file: str) -> None:

    cmd = "rm " + file
    run_cmd(cmd)


def make_bgen_from_vcf(vcf: str) -> None:

    try:
        vcf = dxpy.DXFile(vcf.rstrip())
        print("Processing bcf: " + vcf.describe()['name'])
        vcfprefix = vcf.describe()['name'].rstrip(".bcf") # Get a prefix name for all files
        dxpy.download_dxfile(vcf.get_id(), vcfprefix + ".bcf")
        print("Running file: " + vcfprefix)

        cmd = "plink2 --threads 2 --memory 10000 " \
                  "--bcf /test/" + vcfprefix + ".bcf " \
                  "--export bgen-1.2 'bits='8 'sample-v2' " \
                  "--vcf-half-call r " \
                  "--out /test/" + vcfprefix + " " \
                  "--set-all-var-ids @:#:\$r:\$a " \
                  "--new-id-max-allele-len 100"
        run_cmd(cmd, True)

        purge_file(vcfprefix + ".bcf")

    except Exception as err:
        # Do this as a form of error tracking:
        print("Error in bcf: " + vcf.describe()['name'])
        print(Exception, err)


def make_final_bgen(chromosome: str) -> None:

    coord_file_reader = csv.DictReader(gzip.open('coordinates.files.tsv.gz', mode = 'rt'), delimiter="\t")
    cmd = "cat-bgen"
    is_first = True
    for row in coord_file_reader:
        if row['#chrom'] == chromosome:
            if is_first == True:
                cpcmd = "cp " + row['chunk_prefix'] + ".norm.filtered.tagged.missingness_filtered.annotated.cadd.sample " + chromosome + ".filtered.sample"
                run_cmd(cpcmd)
                is_first = False
            cmd += " -g /test/" + row['chunk_prefix'] + ".norm.filtered.tagged.missingness_filtered.annotated.cadd.bgen"

    cmd += " -og /test/" + chromosome + ".filtered.bgen"
    run_cmd(cmd, True)

    cmd = "bgenix -index -g /test/" + chromosome + ".filtered.bgen"
    run_cmd(cmd, True)


@dxpy.entry_point('main')
def main(chromosome):

    threads = os.cpu_count()
    print('Number of threads available: %i' % threads)

    cmd = "docker pull egardner413/mrcepid-filtering:latest"
    run_cmd(cmd)

    coordinate_file = dxpy.DXFile('file-G7x5910JJv8XZkq44949xbJq')
    dxpy.download_dxfile(coordinate_file.get_id(), "coordinates.files.tsv.gz")

    coord_file_reader = csv.DictReader(gzip.open('coordinates.files.tsv.gz', mode = 'rt'), delimiter="\t")

    # Now build a thread worker that contains as many threads
    # instance takes a thread and 1 thread for monitoring
    available_workers = math.floor((threads - 1) / 2)
    executor = ThreadPoolExecutor(max_workers=available_workers)

    # And launch the requested threads
    future_pool = []
    for row in coord_file_reader:
        if row['#chrom'] == chromosome:
            future_pool.append(executor.submit(make_bgen_from_vcf,
                                               vcf=row['bcf_dxpy']))

    print("All threads submitted...")

    # And gather the resulting futures
    for future in futures.as_completed(future_pool):
        try:
            future.result()
        except Exception as err:
            print("A thread failed...")
            print(Exception, err)

    # Now mash all of the bgen files together
    make_final_bgen(chromosome)

    # Set output
    output = {"bgen": dxpy.dxlink(dxpy.upload_local_file(chromosome + '.filtered.bgen')),
              "index": dxpy.dxlink(dxpy.upload_local_file(chromosome + '.filtered.bgen.bgi')),
              "sample": dxpy.dxlink(dxpy.upload_local_file(chromosome + '.filtered.sample'))}

    return output

dxpy.run()
